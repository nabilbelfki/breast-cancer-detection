{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "portion_size = df.shape[0] // 10\n",
    "array_of_portions = []\n",
    "results = []\n",
    "totalPositive = 0\n",
    "totalNegative = 0\n",
    "totalTruePositive = 0\n",
    "totalTrueNegative = 0\n",
    "totalFalsePositive = 0\n",
    "totalFalseNegative = 0\n",
    "for x in range(10):\n",
    "    start_idx = x * portion_size\n",
    "    end_idx = (x + 1) * portion_size\n",
    "    portion = df.iloc[start_idx:end_idx]\n",
    "    array_of_portions.append(portion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       1.00      0.50      0.67         2\n",
      "           M       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.95      0.75      0.81        12\n",
      "weighted avg       0.92      0.92      0.90        12\n",
      "\n",
      "Accuracy: 0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       1.00      0.88      0.93         8\n",
      "           M       0.80      1.00      0.89         4\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.90      0.94      0.91        12\n",
      "weighted avg       0.93      0.92      0.92        12\n",
      "\n",
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       1.00      1.00      1.00         7\n",
      "           M       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       1.00      1.00      1.00         4\n",
      "           M       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "Accuracy: 0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.80      0.80      0.80         5\n",
      "           M       0.86      0.86      0.86         7\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.83      0.83      0.83        12\n",
      "weighted avg       0.83      0.83      0.83        12\n",
      "\n",
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       1.00      1.00      1.00         9\n",
      "           M       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       1.00      1.00      1.00         9\n",
      "           M       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       1.00      1.00      1.00        10\n",
      "           M       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       1.00      1.00      1.00         7\n",
      "           M       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       1.00      1.00      1.00         9\n",
      "           M       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for df in array_of_portions:\n",
    "    result = {}\n",
    "    X = df.drop(columns=['id', 'diagnosis'])\n",
    "    y = df['diagnosis']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)   \n",
    "\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    TN = conf_matrix[0][0]\n",
    "    FP = conf_matrix[0][1]\n",
    "    FN = conf_matrix[1][0]\n",
    "    TP = conf_matrix[1][1]\n",
    "\n",
    "    P = TP + FN\n",
    "    N = TN + FP\n",
    "\n",
    "    totalPositive += P\n",
    "    totalNegative += N\n",
    "    totalTruePositive += TP\n",
    "    totalTrueNegative += TN\n",
    "    totalFalsePositive += FP\n",
    "    totalFalseNegative += FN\n",
    "\n",
    "    TPR = TP / P\n",
    "    TNR = TN / N\n",
    "    FPR = FP / N\n",
    "    FNR = FN / P\n",
    "\n",
    "    r = TP / P\n",
    "    p = TP / (TP + FP)\n",
    "    F1 = 2 * (p * r) / (p + r)\n",
    "    Acc = (TP + TN) / (P + N)\n",
    "    Err = (FP + FN) / (P + N)\n",
    "    \n",
    "    result['P'] = P\n",
    "    result['N'] = N \n",
    "    result['TP'] = TP\n",
    "    result['TN'] = TN\n",
    "    result['FP'] = FP\n",
    "    result['FN'] = FN\n",
    "    result['TPR'] = str(round(TPR * 100,2)) + '%'\n",
    "    result['TNR'] = str(round(TNR * 100,2)) + '%'\n",
    "    result['FPR'] = str(round(FPR * 100,2)) + '%'\n",
    "    result['FNR'] = str(round(FNR * 100,2)) + '%'\n",
    "    result['r'] = str(round(r * 100,2)) + '%'\n",
    "    result['p'] = str(round(p * 100,2)) + '%'\n",
    "    result['F1'] = str(round(F1 * 100,2)) + '%'\n",
    "    result['Acc'] = str(round(Acc * 100,2)) + '%'\n",
    "    result['Err'] = str(round(Err * 100,2)) + '%'\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'P': 10, 'N': 2, 'TP': 10, 'TN': 1, 'FP': 1, 'FN': 0, 'TPR': '100.0%', 'TNR': '50.0%', 'FPR': '50.0%', 'FNR': '0.0%', 'r': '100.0%', 'p': '90.91%', 'F1': '95.24%', 'Acc': '91.67%', 'Err': '8.33%'}, {'P': 4, 'N': 8, 'TP': 4, 'TN': 7, 'FP': 1, 'FN': 0, 'TPR': '100.0%', 'TNR': '87.5%', 'FPR': '12.5%', 'FNR': '0.0%', 'r': '100.0%', 'p': '80.0%', 'F1': '88.89%', 'Acc': '91.67%', 'Err': '8.33%'}, {'P': 5, 'N': 7, 'TP': 5, 'TN': 7, 'FP': 0, 'FN': 0, 'TPR': '100.0%', 'TNR': '100.0%', 'FPR': '0.0%', 'FNR': '0.0%', 'r': '100.0%', 'p': '100.0%', 'F1': '100.0%', 'Acc': '100.0%', 'Err': '0.0%'}, {'P': 8, 'N': 4, 'TP': 8, 'TN': 4, 'FP': 0, 'FN': 0, 'TPR': '100.0%', 'TNR': '100.0%', 'FPR': '0.0%', 'FNR': '0.0%', 'r': '100.0%', 'p': '100.0%', 'F1': '100.0%', 'Acc': '100.0%', 'Err': '0.0%'}, {'P': 7, 'N': 5, 'TP': 6, 'TN': 4, 'FP': 1, 'FN': 1, 'TPR': '85.71%', 'TNR': '80.0%', 'FPR': '20.0%', 'FNR': '14.29%', 'r': '85.71%', 'p': '85.71%', 'F1': '85.71%', 'Acc': '83.33%', 'Err': '16.67%'}, {'P': 3, 'N': 9, 'TP': 3, 'TN': 9, 'FP': 0, 'FN': 0, 'TPR': '100.0%', 'TNR': '100.0%', 'FPR': '0.0%', 'FNR': '0.0%', 'r': '100.0%', 'p': '100.0%', 'F1': '100.0%', 'Acc': '100.0%', 'Err': '0.0%'}, {'P': 3, 'N': 9, 'TP': 3, 'TN': 9, 'FP': 0, 'FN': 0, 'TPR': '100.0%', 'TNR': '100.0%', 'FPR': '0.0%', 'FNR': '0.0%', 'r': '100.0%', 'p': '100.0%', 'F1': '100.0%', 'Acc': '100.0%', 'Err': '0.0%'}, {'P': 2, 'N': 10, 'TP': 2, 'TN': 10, 'FP': 0, 'FN': 0, 'TPR': '100.0%', 'TNR': '100.0%', 'FPR': '0.0%', 'FNR': '0.0%', 'r': '100.0%', 'p': '100.0%', 'F1': '100.0%', 'Acc': '100.0%', 'Err': '0.0%'}, {'P': 5, 'N': 7, 'TP': 5, 'TN': 7, 'FP': 0, 'FN': 0, 'TPR': '100.0%', 'TNR': '100.0%', 'FPR': '0.0%', 'FNR': '0.0%', 'r': '100.0%', 'p': '100.0%', 'F1': '100.0%', 'Acc': '100.0%', 'Err': '0.0%'}, {'P': 3, 'N': 9, 'TP': 3, 'TN': 9, 'FP': 0, 'FN': 0, 'TPR': '100.0%', 'TNR': '100.0%', 'FPR': '0.0%', 'FNR': '0.0%', 'r': '100.0%', 'p': '100.0%', 'F1': '100.0%', 'Acc': '100.0%', 'Err': '0.0%'}]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'P': 50, 'N': 70, 'TP': 49, 'TN': 67, 'FP': 3, 'FN': 1, 'TPR': '98.0%', 'TNR': '95.71%', 'FPR': '4.29%', 'FNR': '2.0%', 'r': '98.0%', 'p': '94.23%', 'F1': '96.08%', 'Acc': '96.67%', 'Err': '3.33%'}\n"
     ]
    }
   ],
   "source": [
    "TPR = totalTruePositive / totalPositive\n",
    "TNR = totalTrueNegative / totalNegative\n",
    "FPR = totalFalsePositive / totalNegative\n",
    "FNR = totalFalseNegative / totalPositive\n",
    "\n",
    "r = totalTruePositive / totalPositive\n",
    "p = totalTruePositive / (totalTruePositive + totalFalsePositive)\n",
    "F1 = 2 * (p * r) / (p + r)\n",
    "Acc = (totalTruePositive + totalTrueNegative) / (totalPositive + totalNegative)\n",
    "Err = (totalFalsePositive + totalFalseNegative) / (totalPositive + totalNegative)\n",
    "\n",
    "result['P'] = totalPositive\n",
    "result['N'] = totalNegative \n",
    "result['TP'] = totalTruePositive\n",
    "result['TN'] = totalTrueNegative\n",
    "result['FP'] = totalFalsePositive\n",
    "result['FN'] = totalFalseNegative\n",
    "result['TPR'] = str(round(TPR * 100,2)) + '%'\n",
    "result['TNR'] = str(round(TNR * 100,2)) + '%'\n",
    "result['FPR'] = str(round(FPR * 100,2)) + '%'\n",
    "result['FNR'] = str(round(FNR * 100,2)) + '%'\n",
    "result['r'] = str(round(r * 100,2)) + '%'\n",
    "result['p'] = str(round(p * 100,2)) + '%'\n",
    "result['F1'] = str(round(F1 * 100,2)) + '%'\n",
    "result['Acc'] = str(round(Acc * 100,2)) + '%'\n",
    "result['Err'] = str(round(Err * 100,2)) + '%'\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
